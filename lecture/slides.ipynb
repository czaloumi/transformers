{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center>Transformers</center>\n",
    "<center><img src=\"images/transformers-movie.jpeg\"  width=\"75%\" height=\"75%\"/></center>\n",
    "\n",
    "#### <center>Chelsea Zaloumis</center>\n",
    "<center>4/16/21</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "*Disclaimer: It is not my intent to claim any material as my own. The information provided in these slides has been collected and interpreted from various online resources as well as published papers. At the end of the slides is a list of references for all that was used to help build these slides. Quotes and proper citations exist throughout the slides to give credit where it's due.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Objectives\n",
    "---\n",
    "1. Motivation for Transformers\n",
    "    1. What is Seq2Seq modeling?\n",
    "    2. Previous methods and their set backs\n",
    "2. Define Transformers\n",
    "3. Define Self-Attention\n",
    "    1. Self-Attention with vectors\n",
    "    2. Self-Attention with matrices\n",
    "4. Define Multi-Head Attention\n",
    "5. The Encoder-Decoder Attention layer\n",
    "6. Final Linear & Softmax layers\n",
    "7. Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Motivation\n",
    "---\n",
    "Just what do we use Transformers for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A Transformer is a type of neural network architecture developed to solve the problem of **sequence transduction** or **neural machine translation**: any task that transforms an input sequence to an output sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* speech recognition\n",
    "* text-to-speech transformation\n",
    "* language translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Motivation\n",
    "---\n",
    "Useful when words from a sentence refer to phrases prior:\n",
    "\n",
    "\"Tomato basil is my favorite starter because it is surprisingly filling.\" \n",
    "\n",
    "*it* referring to *tomato basil*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Motivation\n",
    "---\n",
    "Other Use Cases:\n",
    "* [Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences](https://www.biorxiv.org/content/10.1101/622803v2)\n",
    "* [Generating Long Sequences with Sparse Transformers](https://arxiv.org/abs/1904.10509)\n",
    "* [Selfie: Self-supervised Pretraining for Image Embedding](https://arxiv.org/abs/1906.02940)\n",
    "* [Behavior Sequence Transformer for E-commerce\n",
    "Recommendation in Alibaba](https://arxiv.org/pdf/1905.06874.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Motivation\n",
    "---\n",
    "Ok but what's Seq2Seq?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Sequence-2-Sequence models take a sequence as input and output another sequence. They are comprised of two components: an **Encoder** and a **Decoder**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"images/seq2seq.png\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Motivation\n",
    "---\n",
    "\n",
    "<center><img src=\"images/seq2seq.png\"/></center>\n",
    "\n",
    "\"The **Encoder** turns each item into a corresponding hidden vector containing the *item and its context*. The **Decoder** reverses the process, turning the vector into an output item, using the previous output as the input context.\" --[seq2seq model in Machine Learning](https://www.geeksforgeeks.org/seq2seq-model-in-machine-learning/)\n",
    "\n",
    "This *context* of each input of the sequence in question is a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
